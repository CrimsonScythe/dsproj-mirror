{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictor_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8YbcRL9azbP",
        "colab_type": "code",
        "outputId": "91c45509-ea70-4d0f-ebed-456fad12156a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import functools\n",
        "import numpy as np\n",
        "from limit_dataset import LimitDataSet\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# prepare LIAR dataset\n",
        "# ##################\n",
        "\n",
        "def func(x):\n",
        "    if (x==\"true\" or x==\"mostly-true\" ):\n",
        "        return 1\n",
        "    elif(x==\"false\" or x==\"barely-true\" or x==\"pants-fire\" or x==\"half-true\"):\n",
        "        return 0\n",
        "\n",
        "df_liar = pd.read_csv('test.tsv', sep='\\t')\n",
        "Xd = df_liar.iloc[:,2]\n",
        "Yd = df_liar.iloc[:,1]\n",
        "\n",
        "X_arr = Xd.to_numpy()\n",
        "\n",
        "Y_arr = Yd.map(func)\n",
        "Y_arr = Y_arr.to_numpy()\n",
        "\n",
        "liar_x = X_arr\n",
        "liar_y = Y_arr\n",
        "\n",
        "####################\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "valid_data = pd.read_csv(\"valid.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "\n",
        "train_x = train_data['content'].to_numpy()\n",
        "train_y = train_data['type_id'].to_numpy()\n",
        "\n",
        "valid_x = valid_data['content'].to_numpy()\n",
        "valid_y = valid_data['type_id'].to_numpy()\n",
        "\n",
        "test_x = test_data['content'].to_numpy()\n",
        "test_y = test_data['type_id'].to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "liar_dataset = tf.data.Dataset.from_tensor_slices((liar_x, liar_y))\n",
        "\n",
        "# print(train_dataset)\n",
        "# print(valid_dataset)\n",
        "# print(test_dataset)\n",
        "\n",
        "# for element, inde in train_dataset:\n",
        "  # print(element.numpy())\n",
        "  # print(inde)\n",
        "\n",
        "\n",
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "\n",
        "# only build vocabulary on training set\n",
        "for content, _ in train_dataset:\n",
        "  some_tokens = tokenizer.tokenize(content.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "\n",
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
        "\n",
        "# example_text = next(iter(train_dataset))[0].numpy()\n",
        "# encoded_example = encoder.encode(example_text)\n",
        "\n",
        "# print(example_text)\n",
        "# print(encoded_example)\n",
        "\n",
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  # py_func doesn't set the shape of the returned tensors.\n",
        "  encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "\n",
        "  # `tf.data.Datasets` work best if all components have a shape set\n",
        "  #  so set the shapes manually: \n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape([])\n",
        "\n",
        "  return encoded_text, label\n",
        "\n",
        "\n",
        "train_encoded_data = train_dataset.map(encode_map_fn)  \n",
        "valid_encoded_data = valid_dataset.map(encode_map_fn)  \n",
        "test_encoded_data = test_dataset.map(encode_map_fn)\n",
        "liar_encoded_data = liar_dataset.map(encode_map_fn)\n",
        "\n",
        "train_batches = train_encoded_data.padded_batch(BATCH_SIZE)\n",
        "valid_batches = valid_encoded_data.padded_batch(BATCH_SIZE)\n",
        "test_batches = test_encoded_data.padded_batch(BATCH_SIZE)\n",
        "liar_batches = liar_encoded_data.padded_batch(BATCH_SIZE)\n",
        "\n",
        "embedding_dim=16\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Embedding(encoder.vocab_size, embedding_dim),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=1,\n",
        "    )\n",
        "\n",
        "\n",
        "result = model.evaluate(test_batches)\n",
        "dict(zip(model.metrics_names, result))\n",
        "\n",
        "result_liar = model.evaluate(liar_batches)\n",
        "dict(zip(model.metrics_names, result_liar))\n",
        "\n",
        "# putting half-true in false gives much higher accuracy :)\n",
        "# it is opposite in the SVM model\n",
        "# please report this in the report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, None, 16)          1785984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_14  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,786,273\n",
            "Trainable params: 1,786,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "4290/4290 [==============================] - 89s 21ms/step - loss: 0.1440 - accuracy: 0.9454\n",
            "537/537 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "127/127 [==============================] - 1s 4ms/step - loss: 1.7540 - accuracy: 0.6461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6461295485496521, 'loss': 1.7540093660354614}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjV7C5b3w1H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}